### p(doom) and Artificial General Intelligence (AGI)
What is the probability of AI taking over or even causing the complete destruction of 
civilization? This question has become a popular topic with the rapid development of generative
AI in recent years[^FAST]. Known as p(doom), or the probability of an AI
apocalypse, this metric is measured on a scale from 1 to 100, with a higher number representing 
the likelihood that AI could evolve into a malignant superintelligence. 

While p(doom) is a sensationalist metric, the disturbing reality is
that many of the top AI scientists, engineers, and executives all have surprising 
high[^PAUSEAI] p(doom) estimates with the mean estimate from AI engineers
of a 40% p(doom) score[^ENGINEERS_SURVEY]. 


### Artificial General Intelligence (AGI)
Artificial General Intelligence (AGI)[^AGI] refers to an AI that surpasses human intelligence 
across a wide range cognitive tasks. A significant concern associated with AGI is that once AI reaches
this threshold, it could rapidly improve itself, becoming an intelligence far beyond anything 
humans can currently comprehend.

#### AI Alignment
Minimizing p(doom) through aligning AGI's goals with our own goals and values is an active area
of research in both academic and by AI companies and should be included in any broad analysis of
the benefits of AGI[^BENEFIT_RISK].

To illustrate misalignment of goals between an AGI and humans, in a 2003 paper[^BOSTROM], Nick Bostrom 
provided an example of a superintelligent AI that has an initial goal to maximize paperclips 
manufacturing. Such an AI could potentially ignore any human values, and in a worst-case scenario,
converting the entire planet into paperclip manufacturing, to the detriment of all life on Earth.

 
## Footnotes
[^FAST]: [P(doom) is AI’s latest apocalypse metric. Here’s how to calculate your score](https://www.fastcompany.com/90994526/pdoom-explained-how-to-calculate-your-score-on-ai-apocalypse-metric)
[^PAUSEAI]: [List of p(doom) values](https://pauseai.info/pdoom)
[^ENGINEERS_SURVEY]: [State of AI Engineering 2023](https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631)
[^AGI]: [Artificial General Intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)
[^BOSTROM]: [Ethical Issues in Advanced Artificial Intelligence](https://nickbostrom.com/ethics/ai)
[^BENEFIT_RISK]: [Benefits & Risks of Artificial Intelligence](https://futureoflife.org/ai/benefits-risks-of-artificial-intelligence/)

